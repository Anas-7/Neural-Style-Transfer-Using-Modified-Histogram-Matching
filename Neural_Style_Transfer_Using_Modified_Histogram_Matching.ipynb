{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUbwUtfXd5rg"
      },
      "outputs": [],
      "source": [
        "# Please click on Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU\n",
        "# Loading the libraries\n",
        "import tensorflow as tf\n",
        "import imutils\n",
        "import threading\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import vgg19\n",
        "from tensorflow.keras.models import Model\n",
        "from PIL import Image\n",
        "import sys\n",
        "from skimage.exposure import match_histograms, equalize_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeOgHR91psCc",
        "outputId": "e31f7191-0f6e-4d11-d459-e5f8da6f0060"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-31dd7901-a7bb-a729-197f-3847bde1cfef)\n"
          ]
        }
      ],
      "source": [
        "# Command for checking GPU in Colab\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9vpSvfGeAiF"
      },
      "outputs": [],
      "source": [
        "#Global Parameters\n",
        "basewidth = baseheight = 512\n",
        "IMAGE_DIRECTORY = \"/content/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKrC8Pnh_WfR"
      },
      "outputs": [],
      "source": [
        "class LoadImages:\n",
        "  def __init__(self, content_image_name, style_image_name):\n",
        "    self.content_image = self.loading_img(content_image_name)\n",
        "    self.style_image = self.loading_img(style_image_name)\n",
        "  \n",
        "  def load(self):\n",
        "    return self.content_image, self.style_image\n",
        "\n",
        "  def load_image_helper(self,im):\n",
        "    im = cv2.resize(im,(basewidth,baseheight))\n",
        "    im = im[...,::-1]\n",
        "    return im\n",
        "\n",
        "  def loading_img(self,image_name):\n",
        "    if ('google.colab' in sys.modules):\n",
        "      try:\n",
        "        im = cv2.imread(IMAGE_DIRECTORY + image_name + \".jpeg\",1)\n",
        "        return self.load_image_helper(im)\n",
        "      except:\n",
        "        try:\n",
        "          im = cv2.imread(IMAGE_DIRECTORY + image_name + \".jpg\",1)\n",
        "          return self.load_image_helper(im)\n",
        "        except:\n",
        "          try:\n",
        "            im = cv2.imread(IMAGE_DIRECTORY + image_name + \".png\",1)\n",
        "            return self.load_image_helper(im)\n",
        "          except:\n",
        "            print(\"The image doesnt exist or the format isnt recognised.\")\n",
        "    else:\n",
        "      try:\n",
        "        im = cv2.imread(IMAGE_DIRECTORY + image_name + \".jpeg\",1)\n",
        "        return self.load_image_helper(im)\n",
        "      except:\n",
        "        try:\n",
        "          im = cv2.imread(IMAGE_DIRECTORY + image_name + \".jpg\",1)\n",
        "          return self.load_image_helper(im)\n",
        "        except:\n",
        "          try:\n",
        "            im = cv2.imread(IMAGE_DIRECTORY + image_name + \".png\",1)\n",
        "            return self.load_image_helper(im)\n",
        "          except:\n",
        "            print(\"The image doesnt exist or the format isnt recognised.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoVujX2bCIPQ"
      },
      "outputs": [],
      "source": [
        "class InputImagePreprocessing:\n",
        "  def __init__(self, enable_normal_method = False, enable_image_blending = True, enable_HSV = False, num_blocks = 4, laplacian_iterations = 5, CLAHE_gridsize = 8, CLAHE_clipLimit = 8.0):\n",
        "    self.enable_normal_method = enable_normal_method\n",
        "    self.enable_image_blending = enable_image_blending\n",
        "    self.enable_HSV = enable_HSV\n",
        "    self.num_blocks = num_blocks\n",
        "    self.laplacian_iterations = laplacian_iterations\n",
        "    self.CLAHE_gridsize = CLAHE_gridsize\n",
        "    self.CLAHE_clipLimit = float(CLAHE_clipLimit)\n",
        "  \n",
        "  def preprocess(self, content_image, style_image):\n",
        "    histogramMatchedImage = self.LocalizedHistogramMatching(content_image, style_image)\n",
        "    clahe_adjusted_image = self.CLAHE_adjustment(histogramMatchedImage)\n",
        "    return clahe_adjusted_image\n",
        "\n",
        "  def CLAHE_adjustment(self, image):\n",
        "    # To deal with the damaged contrast, perform CLAHE. Choose either HSV or LAB color space\n",
        "    if self.enable_HSV == True:\n",
        "      hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
        "      hsv_planes = cv2.split(hsv)\n",
        "      gridsize = self.CLAHE_gridsize\n",
        "      clahe = cv2.createCLAHE(clipLimit = self.CLAHE_clipLimit, tileGridSize = (gridsize,gridsize))\n",
        "      hsv_planes[2] = clahe.apply(hsv_planes[2])\n",
        "      hsv = cv2.merge(hsv_planes)\n",
        "      clahe_adjusted_image = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
        "    else:\n",
        "      # The paper prefers CIELAB space\n",
        "      lab = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
        "      lab_planes = cv2.split(lab)\n",
        "      gridsize = self.CLAHE_gridsize\n",
        "      clahe = cv2.createCLAHE(clipLimit = self.CLAHE_clipLimit, tileGridSize = (gridsize,gridsize))\n",
        "      lab_planes[0] = clahe.apply(lab_planes[0])\n",
        "      lab = cv2.merge(lab_planes)\n",
        "      clahe_adjusted_image = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
        "    \n",
        "    return clahe_adjusted_image\n",
        "\n",
        "  def LocalizedHistogramMatching(self, content_image, style_image):\n",
        "    if not os.path.exists('patches'):\n",
        "      os.makedirs('patches')\n",
        "\n",
        "    nRows = int(self.num_blocks/2)\n",
        "    mCols = int(self.num_blocks/2)\n",
        "\n",
        "    sizeX = content_image.shape[1]\n",
        "    sizeY = content_image.shape[0]\n",
        "\n",
        "    final_map = []\n",
        "    for i in range(0,nRows):\n",
        "      row_maps = []\n",
        "      for j in range(0, mCols):\n",
        "        # roi1 is the content_image being split and roi2 is style image\n",
        "        roi1 = content_image[i*int(sizeY/nRows):i*int(sizeY/nRows) + int(sizeY/nRows) ,j*int(sizeX/mCols):j*int(sizeX/mCols) + int(sizeX/mCols)]\n",
        "        roi2 = style_image[i*int(sizeY/nRows):i*int(sizeY/nRows) + int(sizeY/nRows) ,j*int(sizeX/mCols):j*int(sizeX/mCols) + int(sizeX/mCols)]\n",
        "        cv2.imwrite('patches/content_patch_' + str(i) + str(j) + \".jpg\", roi1)\n",
        "        cv2.imwrite('patches/style_patch_' + str(i) + str(j) + \".jpg\", roi2)\n",
        "        # Perform histogram matching on the patch instead of global image\n",
        "        roi = match_histograms(roi1, roi2, multichannel = True)\n",
        "        row_maps.append(roi)\n",
        "        \n",
        "        cv2.imwrite('patches/matched_patch_'+str(i)+str(j)+\".jpg\", roi)\n",
        "      if self.enable_image_blending == False:\n",
        "        final_map.append(np.hstack(tuple(np.asarray(row_maps))))\n",
        "      else:\n",
        "        # join these two images using image blending\n",
        "        final_map.append(self.LaplacianTransform(row_maps[0], row_maps[1]))\n",
        "\n",
        "    if self.enable_image_blending == False:\n",
        "      local_histogram_image = np.vstack(tuple(final_map))\n",
        "    else:\n",
        "      # join the two blocks vertically using image blending\n",
        "      local_histogram_image = self.LaplacianTransform(final_map[0], final_map[1], horizontal=False)\n",
        "    \n",
        "    return local_histogram_image\n",
        "  \n",
        "  \n",
        "  def LaplacianTransform(self, im1, im2, horizontal = True):\n",
        "    iters = self.laplacian_iterations\n",
        "    # generate Gaussian pyramid for im1\n",
        "    im1_copy = im1.copy()\n",
        "    gp_im1 = [im1_copy]\n",
        "    for i in range(iters):\n",
        "        im1_copy = cv2.pyrDown(im1_copy)\n",
        "        gp_im1.append(im1_copy)\n",
        "\n",
        "    # generate Gaussian pyramid for im2\n",
        "    im2_copy = im2.copy()\n",
        "    gp_im2 = [im2_copy]\n",
        "    for i in range(iters):\n",
        "        im2_copy = cv2.pyrDown(im2_copy)\n",
        "        gp_im2.append(im2_copy)\n",
        "\n",
        "    # generate Laplacian Pyramid for im1\n",
        "    im1_copy = gp_im1[iters - 1]\n",
        "    lp_im1 = [im1_copy]\n",
        "    for i in range(iters - 1, 0, -1):\n",
        "        gaussian_expanded = cv2.pyrUp(gp_im1[i])\n",
        "        laplacian = cv2.subtract(gp_im1[i-1], gaussian_expanded)\n",
        "        lp_im1.append(laplacian)\n",
        "\n",
        "    # generate Laplacian Pyramid for im2\n",
        "    im2_copy = gp_im2[iters - 1]\n",
        "    lp_im2 = [im2_copy]\n",
        "    for i in range(iters - 1, 0, -1):\n",
        "        gaussian_expanded = cv2.pyrUp(gp_im2[i])\n",
        "        laplacian = cv2.subtract(gp_im2[i-1], gaussian_expanded)\n",
        "        lp_im2.append(laplacian)\n",
        "\n",
        "    # Now add left and right halves of images in each level\n",
        "    im1_im2_pyramid = []\n",
        "    n = 0\n",
        "    for im1_lap, im2_lap in zip(lp_im1, lp_im2):\n",
        "        n += 1\n",
        "        cols, rows, ch = im1_lap.shape\n",
        "        if horizontal == True:\n",
        "          laplacian = np.hstack((im1_lap, im2_lap))\n",
        "        else:\n",
        "          laplacian = np.vstack((im1_lap, im2_lap))\n",
        "        im1_im2_pyramid.append(laplacian)\n",
        "    # now reconstruct\n",
        "    im1_im2_reconstruct = im1_im2_pyramid[0]\n",
        "    for i in range(1, iters):\n",
        "        im1_im2_reconstruct = cv2.pyrUp(im1_im2_reconstruct)\n",
        "        im1_im2_reconstruct = cv2.add(im1_im2_pyramid[i], im1_im2_reconstruct)\n",
        "\n",
        "    return im1_im2_reconstruct.astype('uint8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tEcecO3MfX4"
      },
      "outputs": [],
      "source": [
        "class NST:\n",
        "  def __init__(self, input_image, content_image_name, content_image, style_image_name, style_image, STYLE_LAYERS, CONTENT_LAYERS, alpha = 1e-5, beta = 1e-2, optimizer_rate = 7, iterations = 200, enable_normalization = False, enable_normal_method = False):\n",
        "    self.input_image = input_image\n",
        "    self.content_image_name = content_image_name\n",
        "    self.content_image = content_image\n",
        "    self.style_image_name = style_image_name\n",
        "    self.style_image = style_image\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "    self.optimizer_rate = optimizer_rate\n",
        "    self.iterations = iterations\n",
        "    self.STYLE_LAYERS = STYLE_LAYERS\n",
        "    self.CONTENT_LAYERS = CONTENT_LAYERS\n",
        "    self.enable_normalization = enable_normalization\n",
        "    self.enable_normal_method = enable_normal_method\n",
        "    \n",
        "    model = vgg19.VGG19(weights='imagenet',input_shape=(basewidth,baseheight,3),include_top=False)\n",
        "    model.trainable = False\n",
        "    outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "    self.feature_extractor = Model(inputs=model.inputs, outputs=outputs_dict)\n",
        "\n",
        "    self.content_and_style = []\n",
        "    for content_layer,content_weight in self.CONTENT_LAYERS:\n",
        "        self.content_and_style.append((self.feature_extractor(self.preprocess_img(content_image))[content_layer]))\n",
        "\n",
        "    for style_layer,style_weight in self.STYLE_LAYERS:\n",
        "        self.content_and_style.append((self.feature_extractor(self.preprocess_img(style_image))[style_layer]))\n",
        "  \n",
        "  def preprocess_img(self, img):\n",
        "    if self.enable_normalization == False:\n",
        "      img = img.astype('float32')\n",
        "    else:\n",
        "      img = img.astype('float32')/255.0\n",
        "\n",
        "    if (tf.is_tensor(img) == False):\n",
        "      if (len(img.shape) == 3):\n",
        "        img = np.expand_dims(img,axis=0)\n",
        "      img = tf.convert_to_tensor(img)\n",
        "    return img\n",
        "  \n",
        "  def restore_img(self, img):\n",
        "    if (tf.is_tensor(img) == True):\n",
        "      img = img.numpy()\n",
        "    img = np.squeeze(img,axis=0)\n",
        "    if self.enable_normalization == False:\n",
        "      return img\n",
        "    else:\n",
        "      return img * 255.0\n",
        "\n",
        "  def content_cost(self, a_C, a_G):\n",
        "    return tf.reduce_sum(tf.square(tf.subtract(a_C, a_G)))/2\n",
        "\n",
        "  def gram_matrix(self, A):\n",
        "    A = tf.reshape(A, (-1, A.shape[-1])) \n",
        "    gram_matrix = tf.matmul(A, A, transpose_a=True)\n",
        "    return gram_matrix\n",
        "\n",
        "  def style_cost(self, a_S, a_G):\n",
        "    return tf.reduce_sum(tf.square(tf.subtract(self.gram_matrix(a_S), self.gram_matrix(a_G))))\n",
        "\n",
        "  def iteration_loss(self, new_img):\n",
        "    generated_image_model = self.feature_extractor(new_img)  \n",
        "    content_loss = 0\n",
        "    style_loss = 0\n",
        "    track = 0\n",
        " \n",
        "    for content_layer, content_weight in self.CONTENT_LAYERS:\n",
        "      content_loss += content_weight * self.content_cost((generated_image_model[content_layer]), self.content_and_style[track])\n",
        "      track = track + 1\n",
        "    \n",
        "    for style_layer, style_weight in self.STYLE_LAYERS:\n",
        "      style_loss += style_weight * self.style_cost((generated_image_model[style_layer]), self.content_and_style[track])\n",
        "      track = track + 1\n",
        "    \n",
        "    tv_loss = tf.reduce_sum(tf.image.total_variation(new_img))\n",
        "    if self.enable_normal_method == True:\n",
        "      self.normal_content_losses.append(self.alpha * content_loss)\n",
        "      self.normal_style_losses.append(self.beta * style_loss)\n",
        "    else:\n",
        "      self.local_content_losses.append(self.alpha * content_loss)\n",
        "      self.local_style_losses.append(self.beta * style_loss)\n",
        "    \n",
        "    total_loss = self.beta * style_loss + self.alpha * content_loss + tv_loss\n",
        "    return total_loss\n",
        "\n",
        "  def plotTotalLoss(self):\n",
        "    plt.plot((self.normal_losses),label='Normal method')\n",
        "    plt.plot((self.local_losses),label='Proposed method')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Log (Total Loss)')\n",
        "    plt.legend()\n",
        "    plt.savefig('Total_loss.jpeg')\n",
        "    plt.close()\n",
        "  \n",
        "  def plotContentLoss(self):\n",
        "    plt.plot(np.log10(self.normal_content_losses),label='Normal method')\n",
        "    plt.plot(np.log10(self.local_content_losses),label='Proposed method')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Log (Content Loss)')\n",
        "    plt.legend()\n",
        "    plt.savefig('Content_loss.jpeg')\n",
        "    plt.close()\n",
        "  \n",
        "  def plotStyleLoss(self):\n",
        "    plt.plot(np.log10(self.normal_style_losses),label='Normal method')\n",
        "    plt.plot(np.log10(self.local_style_losses),label='Proposed method')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Log (Style Loss)')\n",
        "    plt.legend()\n",
        "    plt.savefig('Style_loss.jpeg')\n",
        "    plt.close()\n",
        "\n",
        "  def double_mode(self):\n",
        "    self.single_mode(normal_method = True)\n",
        "    self.single_mode(normal_method = False)\n",
        "\n",
        "  def single_mode(self, normal_method = False, print_loss = False):\n",
        "    \n",
        "    if normal_method == False:\n",
        "      self.enable_normal_method = False\n",
        "      self.local_losses = []\n",
        "      self.local_content_losses = []\n",
        "      self.local_style_losses = []\n",
        "    else:\n",
        "      self.enable_normal_method = True\n",
        "      self.normal_losses = []\n",
        "      self.normal_content_losses = []\n",
        "      self.normal_style_losses = []\n",
        "      \n",
        "    if self.enable_normal_method == True:\n",
        "      new_img = self.content_image\n",
        "    else:\n",
        "      new_img = self.input_image \n",
        "\n",
        "    if self.enable_normalization == False:\n",
        "      new_img = tf.Variable(self.preprocess_img(new_img))\n",
        "    else:\n",
        "      new_img = tf.Variable(self.preprocess_img(new_img))\n",
        "    \n",
        "    opt = tf.optimizers.Adam(self.optimizer_rate)\n",
        "    for i in range(1,self.iterations + 1):\n",
        "      with tf.GradientTape(persistent = False) as g:\n",
        "        g.watch(new_img)\n",
        "        total_loss = self.iteration_loss(new_img)\n",
        "        if print_loss == True:\n",
        "          print(\"Iteration: \" + str(i) + \" Loss: \" + str(total_loss.numpy()))\n",
        "        grad = g.gradient(total_loss, new_img)\n",
        "        opt.apply_gradients(zip([grad],[new_img]))\n",
        "\n",
        "        if self.enable_normal_method == True:\n",
        "          self.normal_losses.append(np.log10(total_loss.numpy()))\n",
        "        else:\n",
        "          self.local_losses.append(np.log10(total_loss.numpy()))\n",
        "\n",
        "        if self.enable_normalization == False:\n",
        "          new_img.assign(tf.clip_by_value(new_img, 0.0, 255.0))\n",
        "        else:\n",
        "          new_img.assign(tf.clip_by_value(new_img, 0.0, 1.0))\n",
        "\n",
        "        if (i % 20 == 0):\n",
        "          generated_image = self.restore_img(new_img)\n",
        "          im = Image.fromarray(generated_image.astype('uint8'),'RGB')\n",
        "          if normal_method == False:           \n",
        "            im.save(\"op_\" + str(i) + \"_local.png\")\n",
        "          else:\n",
        "            im.save(\"op_\" + str(i) + \"_normal.png\")\n",
        "      \n",
        "      generated_image = self.restore_img(new_img)\n",
        "      # Convert the image to Image object so that save method can be used on it\n",
        "      output_image = Image.fromarray(generated_image.astype('uint8'),'RGB')\n",
        "      if normal_method == False:\n",
        "        output_image.save(self.content_image_name + \"+\" + self.style_image_name + \"+histogram+local.png\")\n",
        "      else:\n",
        "        output_image.save(self.content_image_name + \"+\" + self.style_image_name + \"+histogram+normal.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyG0GRdpaRAG"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  # Images are loaded in RGB format\n",
        "  content_image_name=\"dielit\"\n",
        "  style_image_name=\"johnson_style\"\n",
        "  content_image, style_image = LoadImages(content_image_name = content_image_name,\n",
        "                                          style_image_name = style_image_name).load()\n",
        "  input_image_preprocessor = InputImagePreprocessing()\n",
        "  input_image = input_image_preprocessor.preprocess(content_image, style_image)\n",
        "  STYLE_LAYERS = [\n",
        "    ('block1_conv1', 0.2),\n",
        "    ('block2_conv1', 0.2),\n",
        "    ('block3_conv1', 0.2),\n",
        "    ('block4_conv1', 0.2),\n",
        "    (\"block5_conv1\",0.2)]\n",
        "  CONTENT_LAYERS = [\n",
        "    (\"block4_conv1\",1)]\n",
        "  nst = NST(input_image, content_image_name, content_image,\n",
        "            style_image_name, style_image, STYLE_LAYERS, CONTENT_LAYERS)\n",
        "  # nst.double_mode()\n",
        "  # nst.plotTotalLoss()\n",
        "  # nst.plotContentLoss()\n",
        "  # nst.plotStyleLoss()\n",
        "\n",
        "  nst.single_mode()\n",
        "  \n",
        "if __name__==\"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X96_ARpcpUpQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
